#!/usr/bin/env python3

from pathlib import Path
from typing import Any
import argparse
import collections
import contextlib
import fnmatch
import gzip
import json
import multiprocessing.pool
import os
import shutil
import subprocess
import sys
import tarfile
import tempfile
import urllib.error
import urllib.request

try:
    import tomllib as tl
except ImportError:
    try:
        import toml as tl
    except ImportError:
        tl = None


_SUPPORTED_OS = {
    "bionic",
    "focal",
    "jammy",
    "macos",
    "noble",
}


Arch = collections.namedtuple("Arch", ["id", "ubuntu_id", "ubuntu_mirror"])

ARM64 = Arch("aarch64", "arm64", "http://ports.ubuntu.com/ubuntu-ports")
X86_64 = Arch("x86_64", "amd64", "http://gb.archive.ubuntu.com/ubuntu")


@contextlib.contextmanager
def restore_pwd():
    pwd = os.getcwd()
    try:
        yield
    finally:
        os.chdir(pwd)


def _get_required(obj: dict[str, Any], key: str) -> Any:
    if key not in obj or not obj[key]:
        raise SystemExit(f"error: {key} must exist and be non null")

    return obj[key]


def _setup_sysroot(suffix: str) -> Path:
    sysroot_dir = Path(f"sysroot-{suffix}")
    if sysroot_dir.is_dir():
        shutil.rmtree(sysroot_dir)
    elif sysroot_dir.exists():
        sysroot_dir.unlink()
    if sysroot_dir.exists():
        raise SystemExit(
            f"error: failed to remove '{sysroot_dir}', please delete it and re-run"
        )
    sysroot_dir.mkdir()
    return sysroot_dir


def _find_data_archive(dirname: Path):
    for ext in ("zstd", "xz"):
        path = dirname / f"data.tar.{ext}"
        if path.exists():
            return path
    raise SystemExit(f"error: failed to find data.tar.zst or data.tar.xz in {dirname}")


def _download_and_extract_package(name: str, url: str, package_dir: Path) -> None:
    name = url.split("/")[-1]
    output_path = Path(f"/tmp/{name}.deb")
    try:
        urllib.request.urlretrieve(url, output_path)
    except urllib.error.HTTPError as e:
        print(
            f"error: failed to download {name} from {url}: {e}",
            file=sys.stderr,
        )
        raise
    with tempfile.TemporaryDirectory() as dirname:
        dirname = Path(dirname)
        with restore_pwd():
            os.chdir(dirname)
            subprocess.check_output(["ar", "x", output_path])
            archive = _find_data_archive(dirname)
            package_dir.mkdir(parents=True, exist_ok=True)
            subprocess.check_output(
                [
                    "tar",
                    "xf",
                    archive,
                    "-C",
                    package_dir,
                ]
            )


def _download_packages(
    ubuntu_release: str,
    arch: Arch,
    packages: set[str],
    sysroot_dir: Path,
) -> None:
    package_archive = Path(f"/tmp/packages-{ubuntu_release}-{arch.id}.gz")
    if not package_archive.exists():
        print(f"Downloading package list for {ubuntu_release}-{arch.id}...")
        package_url = f"{arch.ubuntu_mirror}/dists/{ubuntu_release}/main/binary-{arch.ubuntu_id}/Packages.gz"
        # TODO: progress reporting
        urllib.request.urlretrieve(package_url, package_archive)

    with gzip.open(package_archive, "rb") as f:
        files = [
            x for x in f.read().decode().splitlines() if x.startswith("Filename: ")
        ]

    package_paths = {}
    needed_packages = set(packages)
    for filename in files:
        if not needed_packages:
            break
        for package in needed_packages:
            # Filename: pool/main/c/curl/libcurl4-openssl-dev_7.68.0-1ubuntu2_amd64.deb
            last_component = filename.split("/")[-1]
            if last_component.startswith(f"{package}_"):
                package_paths[package] = filename.split(" ")[-1]
                needed_packages.remove(package)
                break

    missing_packages = packages - set(package_paths.keys())
    if missing_packages:
        raise SystemExit(
            "Failed to find some packages, please report this issue: {}".format(
                " ".join(sorted(missing_packages))
            )
        )

    pool = multiprocessing.pool.Pool()
    results = []
    for name, path in package_paths.items():
        results.append(
            pool.apply_async(
                _download_and_extract_package,
                (name, f"{arch.ubuntu_mirror}/{path}", sysroot_dir.absolute()),
            )
        )

    pool.close()
    pool.join()

    for result in results:
        if not result.successful():
            raise SystemExit(f"error: {result.get()}")


def _cleanup_linux_sysroot(
    arch: Arch,
    deleted_patterns: list[str],
    sysroot_dir: Path,
) -> None:
    broken_libraries_dir = Path("usr") / "lib" / f"{arch.id}-linux-gnu"
    destination_dir = Path("lib") / f"{arch.id}-linux-gnu"

    with restore_pwd():
        os.chdir(sysroot_dir.absolute())
        _remove_matching_patterns(Path("."), deleted_patterns)
        _fix_package_symlinks(broken_libraries_dir, destination_dir)

        # NOTE: Only exists for x86_64, and maybe not future ubuntu releases
        lib64_path = Path("lib64")
        if lib64_path.exists():
            _fix_package_symlinks(lib64_path, destination_dir)

    _validate_relative_symlinks(sysroot_dir)


def _write_bazel_files(sysroot_dir: Path) -> None:
    name = sysroot_dir.name
    (sysroot_dir / "BUILD.bazel").write_text(f"""\
filegroup(
    name = "{name}",
    srcs = glob(["**"]),
    visibility = ["//visibility:public"],
)
""")
    (sysroot_dir / "MODULE.bazel").write_text(f'module(name = "{name}")\n')


def _archive(sysroot_dir: Path) -> None:
    # https://stackoverflow.com/questions/1094841/get-a-human-readable-version-of-a-file-size
    def sizeof_fmt(num):
        for unit in ("", "Ki", "Mi", "Gi", "Ti", "Pi", "Ei", "Zi"):
            if abs(num) < 1024.0:
                return f"{num:3.1f} {unit}B"
            num /= 1024.0
        return f"{num:.1f} YiB"

    output = Path(f"{sysroot_dir.name}.tar.xz")
    output.unlink(missing_ok=True)
    with tarfile.open(output, "w:xz") as tar:
        tar.add(sysroot_dir, arcname="")

    size = output.stat().st_size
    print(f"{output}: {sizeof_fmt(size)}")


def _fix_package_symlinks(broken_libraries_dir: Path, destination_dir: Path) -> None:
    assert broken_libraries_dir.exists(), broken_libraries_dir
    assert destination_dir.exists(), destination_dir

    relative_root = Path(".")
    for _ in range(0, len(broken_libraries_dir.parts)):
        relative_root /= ".."

    relative_root /= destination_dir

    # relative_root = Path(os.path.relpath(broken_libraries_dir, destination_dir))
    for lib in broken_libraries_dir.glob("*.so*"):
        # Skip normal files
        if not lib.is_symlink():
            continue

        # Skip symlinks to relative paths that already exist inside the sysroot
        # TODO: this should validate the relative-ness actually lives inside the sysroot
        if not lib.readlink().is_absolute():
            continue

        dest = relative_root / lib.readlink().name
        lib.unlink()
        lib.symlink_to(dest)

        if not lib.exists():
            print(
                f"WARNING: deleting dead symlink: {lib} (you might want to install the providing package instead)"
            )
            lib.unlink()


def _remove_matching_patterns(sysroot: Path, patterns: list[str]) -> None:
    def _should_delete(name: Path, patterns: list[str]) -> bool:
        return any(fnmatch.fnmatch(str(name), x) for x in patterns)

    for root, dirs, files in os.walk(str(sysroot)):
        for dir in dirs:
            path = Path(root) / dir
            if _should_delete(path, patterns):
                shutil.rmtree(path)

        for file in files:
            path = Path(root) / file
            if _should_delete(path, patterns):
                path.unlink()


# NOTE: this should be solved by the symlink re-writing, but this is another safety net
def _validate_relative_symlinks(root: Path) -> None:
    for _, _, files in os.walk(str(root)):
        for file in files:
            path = Path(root) / file
            if path.is_symlink():
                if path.readlink().absolute():
                    raise SystemExit(f"{path}: error: expected a relative symlink")


def _generate_ubuntu_sysroot(os_name: str, platform: dict[str, Any]) -> None:
    packages = set(_get_required(platform, "packages"))
    deleted_patterns = platform.get("deleted_patterns") or []
    archs = _get_required(platform, "archs")
    for arch_str in archs:
        if arch_str in ("aarch64", "arm64"):
            arch = ARM64
        elif arch_str in ("amd64", "x86_64"):
            arch = X86_64
        else:
            raise SystemExit(
                f"error: unsupported arch '{arch_str}', valid options: aarch64, x86_64"
            )

        sysroot_dir = _setup_sysroot(f"{os_name}-{arch.id}")
        _download_packages(os_name, arch, packages, sysroot_dir)
        _cleanup_linux_sysroot(arch, deleted_patterns, sysroot_dir)
        _write_bazel_files(sysroot_dir)
        _archive(sysroot_dir)


def _generate_macos_sysroot(platform: dict[str, Any]) -> None:
    sysroot_dir = _setup_sysroot(f"macos")
    system_sysroot = (
        subprocess.check_output(["xcrun", "--show-sdk-path", "--sdk", "macosx"])
        .decode()
        .strip()
    )
    shutil.copytree(
        system_sysroot,
        sysroot_dir,
        symlinks=True,
        dirs_exist_ok=True,
    )

    deleted_patterns = platform.get("deleted_patterns") or []
    with restore_pwd():
        os.chdir(sysroot_dir.absolute())
        _remove_matching_patterns(Path("."), deleted_patterns)

    _validate_relative_symlinks(sysroot_dir)
    _write_bazel_files(sysroot_dir)
    _archive(sysroot_dir)


def _main(platforms: list[dict[str, Any]]) -> None:
    for platform in platforms:
        os = _get_required(platform, "os")
        if os not in _SUPPORTED_OS:
            raise SystemExit(
                f"error: unsupported os '{os}', valid options: {', '.join(sorted(_SUPPORTED_OS))}"
            )

        if os == "macos":
            _generate_macos_sysroot(platform)
        else:
            _generate_ubuntu_sysroot(os, platform)


def _build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--config",
        help="The config file to read from, defaults to 'sysroot-config.(toml|json)'",
    )
    return parser


if __name__ == "__main__":
    args = _build_parser().parse_args()
    config_file = args.config
    if not config_file:
        if os.path.exists("sysroot-config.json"):
            config_file = "sysroot-config.json"
        elif os.path.exists("sysroot-config.toml"):
            config_file = "sysroot-config.toml"

    if not os.path.exists(config_file):
        raise SystemExit(
            f"{config_file}: error: file does not exist, use --config to pass another path"
        )

    with open(config_file) as f:
        contents = f.read()
        try:
            config = json.loads(contents)
        except json.JSONDecodeError:
            if not tl:
                raise SystemExit(
                    "error: to use toml, either use python3.11 or run 'pip3 install toml'. Otherwise use json instead"
                )
            config = tl.loads(contents)

    platforms = _get_required(config, "platforms")
    _main(platforms)
